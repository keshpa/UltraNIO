#!/usr/bin/python3

from kubernetes import client, config
import yaml
import os
import configparser
from kubernetes.client.rest import ApiException
import subprocess
import ipaddress


on_host = os.getenv('ON_HOST', 'true').lower() != 'false'

class Config:
    def __init__(self, etcd_data_dir: str, etcd_server_port: int, etcd_client_port: int, kubernetes_service_cidr: str, kubernetes_coredns_cidr: str, version: str):
        if not on_host and not etcd_data_dir.startswith("/host/"):
            etcd_data_dir = "/host/" + etcd_data_dir
        self.etcd_data_dir = etcd_data_dir
        self.etcd_server_port = etcd_server_port
        self.etcd_client_port = etcd_client_port
        self.kubernetes_service_cidr = kubernetes_service_cidr
        self.kubernetes_coredns_cidr = kubernetes_coredns_cidr
        self.version = version

def get_service_cidr():
    # Load the Kubernetes config (assumes running in-cluster or with kubeconfig)
    config.load_kube_config()  # Use config.load_incluster_config() if running inside a cluster

    # Create a CoreV1Api client
    v1 = client.CoreV1Api()

    try:
        # Retrieve the kube-proxy or kube-apiserver ConfigMap in the kube-system namespace
        config_map = v1.read_namespaced_config_map("kube-apiserver", "kube-system")

        # Check for service CIDR configuration in ConfigMap data
        service_cidr = config_map.data.get("service-cluster-ip-range", None)

        if service_cidr:
            return service_cidr
        else:
            return None
    except client.exceptions.ApiException as e:
        return None


def get_kube_apiserver_service_cidr():
    # Load kubeconfig (use config.load_incluster_config() for in-cluster environments)
    config.load_kube_config()

    # Connect to CoreV1 API
    v1 = client.CoreV1Api()

    # Look for kube-apiserver pods in the kube-system namespace
    pods = v1.list_namespaced_pod(namespace="kube-system")
    for pod in pods.items:
        if "kube-apiserver" in pod.metadata.name:
            if pod.spec.containers:
                for container in pod.spec.containers:
                    service_cidr = extract_service_cluster_ip_range(container.command) # Look for --service-cluster-ip-range
                    if service_cidr:
                        return service_cidr
    return None

def extract_service_cluster_ip_range(args):
    for arg in args:
        if arg.startswith("--service-cluster-ip-range="):
            return arg.split("=", 1)[1]  # Extract the value after '='
    return None  # Return None if not found


def extract_service_cidr(file_path):
    """
    Extract the service CIDR from the given kube-apiserver configuration file.
    Handles both static pod manifests and key-value configuration files.

    :param file_path: Path to the configuration file
    :return: The extracted service CIDR or None if not found
    """
    if not os.path.exists(file_path):
        return None

    try:
        # Open the file and parse as YAML
        with open(file_path, "r") as file:
            config = yaml.safe_load(file)

            # Check if it's a static pod manifest (YAML format)
            if isinstance(config, dict) and 'spec' in config:
                containers = config['spec'].get('containers', [])
                for container in containers:
                    if 'kube-apiserver' in container.get('name', ''):
                        for arg in container.get('command', []):
                            if arg.startswith("--service-cluster-ip-range="):
                                return arg.split("=", 1)[1]

            # Check if it's a key-value configuration file
            if isinstance(config, dict):
                if 'service-cluster-ip-range' in config:
                    return config['service-cluster-ip-range']

        return None

    except yaml.YAMLError as e:
        return None
    except Exception as e:
        return None


def retrieve_kubernetes_service_cidr():
    # Paths to check for configuration files
    file_paths = [
        "/etc/kubernetes/manifests/kube-apiserver.yaml",
        "/etc/kubernetes/config.yaml",
    ]

    # Try to read and extract Service CIDR from available files
    for file_path in file_paths:
        service_cidr = extract_service_cidr(file_path)
        if service_cidr:
            return service_cidr

    args = get_service_cidr()
    if args:
        service_cidr = extract_service_cluster_ip_range(args)
        if service_cidr:
            return service_cidr

    service_cidr = get_kube_apiserver_service_cidr()
    if service_cidr:
        return service_cidr

    return None

def update_ultra_bootstrap_configuration(config: Config, bootstrap_file):
    ultra_config = configparser.ConfigParser()
    ultra_config.optionxform = str
    if os.path.exists(bootstrap_file):
        ultra_config.read(bootstrap_file)

    try:
        if not ultra_config.has_section("general"):
            ultra_config.add_section("general")

        ultra_config.set("general", "VERSION", config.version)

        if not ultra_config.has_section("etcd"):
            ultra_config.add_section("etcd")
        ultra_config.set("etcd", "ETCD_DATA_DIR", config.etcd_data_dir)
        ultra_config.set("etcd", "ETCD_SERVER_PORT", config.etcd_server_port)
        ultra_config.set("etcd", "ETCD_CLIENT_PORT", config.etcd_client_port)

        if not ultra_config.has_section("kubernetes"):
            ultra_config.add_section("kubernetes")
        ultra_config.set("kubernetes", "SERVICE_CIDR", config.kubernetes_service_cidr)
        ultra_config.set("kubernetes", "CORE_DNS_CIDR", config.kubernetes_coredns_cidr)

        with open(bootstrap_file, 'w') as configfile:
            ultra_config.write(configfile)
    except Exception as e:
        print("Error: Failed to write Ultra-nio-bootstrap configuration file. Ultra-NIO will not work.", e)
        return False

def get_input(prompt, default=None, validation_fn=None):
    """
    Get user input with a prompt, default value, and optional validation function.

    :param prompt: The input prompt to show the user
    :param default: The default value to use if the user provides no input
    :param validation_fn: A function to validate the input (returns True if valid)
    :return: Validated user input
    """
    while True:
        if prompt == "":
            user_input = input().strip()
        else:
            user_input = input(f"{prompt} [{default}]: ").strip()
        if not user_input and default is not None:
            return default
        if validation_fn and not validation_fn(user_input):
            print("Invalid input. Please try again.")
        else:
            return user_input

def validate_port(port):
    """Validate if the input is a valid port number (1-65535)."""
    try:
        port = int(port)
        return 1 <= port <= 65535
    except ValueError:
        return False

def validate_cidr(cidr):
    """Validate if the input is a valid CIDR block."""
    try:

        ipaddress.ip_network(cidr)
        return True
    except ValueError:
        return False

def validate_path(path):
    """Validate if the input is a valid writable path."""
    try:
        if os.path.exists(path) or os.access(os.path.dirname(path) or ".", os.W_OK):
            return True
        return False
    except Exception:
        return False

# Input YAML string
Ultra_NIO_pod_deployment_conf_string = """
apiVersion: apps/v1
kind: DaemonSet
metadata:
  name: ultra-nio-daemonset
  namespace: kube-system
spec:
  selector:
    matchLabels:
      app: ultra-nio-daemon
  template:
    metadata:
      labels:
        app: ultra-nio-daemon
    spec:
      hostPID: true  # Allows the container to observe host process IDs
      containers:
      - name: ultra-nio
        image: docker.io/gkpatwardhan/ultra-nio:latest
        imagePullPolicy: IfNotPresent
        command:
          - /start.sh
        securityContext:
          privileged: true
        ports:
        - containerPort: 8080  # Example port
        env:
        - name: NODE_NAME
          valueFrom:
            fieldRef:
              fieldPath: spec.nodeName
        - name: POD_NAME
          valueFrom:
            fieldRef:
              fieldPath: metadata.name
        - name: HOST_IP
          valueFrom:
            fieldRef:
              fieldPath: status.hostIP
        - name: ON_HOST
          value: "false"
        volumeMounts:
          - name: host
            mountPath: /host
      hostNetwork: true  # Share the host's IP address
      dnsPolicy: ClusterFirstWithHostNet  # Ensure DNS works with host network
      tolerations:  # Allow scheduling on all nodes
      - operator: "Exists"
      volumes:
      - name: host
        hostPath:
          path: /
          type: Directory
"""

def create_ultra_nio_daemonset_yaml(file_path):
    # Deserialize YAML string into a Python dictionary
    data = yaml.safe_load(Ultra_NIO_pod_deployment_conf_string)

    # Serialize Python dictionary back to YAML and write it to a file
    with open(file_path, "w") as file:
        yaml.dump(data, file, default_flow_style=False)

def deploy_ultra_nio_daemonset_with_kubectl(file_path):
    try:
        # Run the kubectl apply command to deploy the DaemonSet
        result = subprocess.run(
            ["kubectl", "apply", "-f", file_path],
            stdout=subprocess.PIPE,
            stderr=subprocess.PIPE,
            text=True
        )

        # Check if the command succeeded
        if result.returncode == 0:
            print(f"DaemonSet successfully deployed:\n{result.stdout}")
        else:
            print(f"Error deploying DaemonSet:\n{result.stderr}")

    except FileNotFoundError:
        print("Error: kubectl CLI is not installed or not in PATH.")
    except Exception as e:
        print(f"An unexpected error occurred: {e}")


ultra_nio_daemonset_file = "/etc/ultra-nio/ultra-nio-daemonset.yaml"
if __name__ == "__main__":

    print("At this step, you'll bootstrap the Ultra-NIO CNI for your Kubernrtes cluster. It is very important that this"
        "\nscript not be run after Ultra-NIO has already been deployed. Running this script again will destroy any previously"
        "\nconfigured Ultra-NIO networking constructs."
        "\nAre you sure you want to continue [yes/no]: ", end="")
    continue_with_bootstrap = get_input(
        "",
        default="No",
        validation_fn=None
    )

    if continue_with_bootstrap.lower() != "yes":
        print("Exiting as requested ...")
        exit(0)

    # Prompt user for inputs
    print("Enter the configuration details for Ultra-NIO:")

    etcd_server_port = get_input(
        "Enter Ultra-NIO's ETCD server port:",
        default="1026",
        validation_fn=validate_port
    )

    etcd_client_port = get_input(
        "Enter Ultra-NIO's ETCD client port:",
        default="1027",
        validation_fn=validate_port
    )

    kubernetes_service_cidr = retrieve_kubernetes_service_cidr()
    print(f"Kubernetes service cidr detected as: {kubernetes_service_cidr}")

    k8n_cidrs_intersect = True
    while k8n_cidrs_intersect:
        kubernetes_coredns_cidr = get_input(
            "Enter CIDR space for Kubernetes COREDNS service to run:",
            default="10.97.0.0/20",
            validation_fn=validate_cidr
        )
        network1 = ipaddress.ip_network(kubernetes_service_cidr, strict=False)
        network2 = ipaddress.ip_network(kubernetes_coredns_cidr, strict=False)
    
        if network1.overlaps(network2):
            print("CIDR overlaps with Kubernetes service cidr. Retry ...")
        else:
            k8n_cidrs_intersect = False

    ultra_etcd_data_dir=""
    if not on_host:
        ultra_etcd_data_dir = "/host/" + "/var/lib/etcd-ultra-nio"
    else:
        ultra_etcd_data_dir = "/var/lib/etcd-ultra-nio"

    data_file_location = get_input(
        "Enter the location to store Ultra-NIO configuration data: ",
        default=ultra_etcd_data_dir,
        validation_fn=validate_path
    )
    print("\nConfiguration Details:")
    print(f"ETCD Server Port: {etcd_server_port}")
    print(f"ETCD Client Port: {etcd_client_port}")
    print(f"DNS CIDR: {kubernetes_coredns_cidr}")
    print(f"Kubernetes service_cidr: {kubernetes_service_cidr}")
    print(f"Data File Location: {data_file_location}")

    bootstrap_file = ""
    if not on_host:
        bootstrap_file = "/host/" + "/etc/ultra-nio/ultra-nio.conf"
    else:
        bootstrap_file = "/etc/ultra-nio/ultra-nio.conf"

    update_ultra_bootstrap_configuration(Config(data_file_location, etcd_server_port, etcd_client_port, kubernetes_service_cidr, kubernetes_coredns_cidr, version="1.0"), bootstrap_file)
    create_ultra_nio_daemonset_yaml(ultra_nio_daemonset_file)
    deploy_ultra_nio_daemonset_with_kubectl(ultra_nio_daemonset_file)

